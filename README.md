# ğŸ’¾ Ultra-Fast Bitcoin Address Importer (SQLite Optimized)

> âš™ï¸ **High-performance tool for bulk importing Bitcoin addresses into SQLite**  
> This script is designed to efficiently **load millions of addresses** line-by-line  
> into a local SQLite database with **maximum speed**, **progress tracking**,  
> and **real-time counters**.

---

## ğŸš€ Overview

This tool imports a huge list of Bitcoin addresses (e.g., from a text file)  
into an SQLite database (`addresses11.db`).  

Itâ€™s optimized for speed using:
- ğŸš€ PRAGMA optimizations  
- ğŸ§® Batched inserts  
- ğŸ” Real-time progress updates via multiprocessing  
- ğŸ’¾ Single-transaction commit (massively faster than per-line commits)

The importer is ideal for creating or populating large **address lookup databases**  
for later blockchain analysis or seed-checking tools.

---

## âœ¨ Features

| Feature | Description |
|----------|--------------|
| âš™ï¸ **SQLite PRAGMA optimization** | Turns off journaling & sync for raw speed |
| ğŸ“Š **Live progress indicator** | Displays import progress with dynamic updates |
| ğŸ’¾ **Single-transaction bulk insert** | Commits once at the end for maximum efficiency |
| ğŸ§® **Address filtering** | Imports only Bitcoin-style addresses (1, 3, bc1) |
| ğŸ§  **Automatic total estimation** | Estimates total records from file size |
| ğŸ§µ **Threaded UI counter** | Updates status in real time during import |
| ğŸ§° **Safe deduplication** | Uses `INSERT OR IGNORE` to skip duplicates automatically |

---

## ğŸ“‚ File Structure

| File | Description |
|------|-------------|
| `import_addresses.py` | Main script |
| `adresy21.txt` | Input text file containing addresses (one per line) |
| `addresses11.db` | Output SQLite database |
| `README.md` | This documentation |

---

## âš™ï¸ Configuration

| Variable | Description |
|-----------|-------------|
| `file_path` | Path to input address file (default: `adresy21.txt`) |
| `db_file` | SQLite database file name (default: `addresses11.db`) |
| `batch` | Number of addresses inserted per batch (10 million) |
| `total_guess` | Estimated total addresses (based on file size / 64 bytes) |

**Dependencies**

No external libraries required.  
Python standard libraries: `os`, `time`, `threading`, `multiprocessing`, `sqlite3`.

---

## ğŸ§  How It Works

### 1ï¸âƒ£ Estimate Total  
Before import, the script estimates total records by dividing the file size by ~64 bytes per line.

```python
total_guess = os.path.getsize(file_path) // 64
2ï¸âƒ£ Initialize Progress Thread

A live progress display runs in a separate thread, updating every second:

print(f"ğŸ“Š POSTÄ˜P: {current} / ~{total_guess} adresÃ³w ({percent:.2f}%)", end='\r')

3ï¸âƒ£ SQLite Optimization

The script sets fast-write PRAGMA options for high-speed importing:

conn.execute('PRAGMA synchronous = OFF')
conn.execute('PRAGMA journal_mode = OFF')
conn.execute('PRAGMA locking_mode = EXCLUSIVE')
conn.execute('PRAGMA temp_store = MEMORY')
conn.execute('PRAGMA cache_size = 1000000')


This drastically improves bulk performance (10Ã—â€“100Ã— faster).

4ï¸âƒ£ Address Filtering

Only valid Bitcoin-style addresses are inserted (those starting with 1, 3, or b):

if address and address[0] in ("1", "3", "b"):
    batch.append((address,))

5ï¸âƒ£ Batched Insert + Final Commit

Addresses are inserted in batches (10 million rows per block).
One single commit at the end avoids slow disk I/O loops.

c.executemany('INSERT OR IGNORE INTO addresses (address) VALUES (?)', batch)
conn.commit()

ğŸ§¾ Example Output
ğŸ” Szacowana liczba adresÃ³w: ~31500000
ğŸ“Š POSTÄ˜P: 14560000 / ~31500000 adresÃ³w (46.22%) 
âœ… GOTOWE: 31500420 adresÃ³w zaÅ‚adowanych.
âœ… Import zakoÅ„czony.

ğŸ§© Core Functions
Function	Description
print_counter()	Displays real-time progress and completion percentage
import_addresses_line_by_line()	Imports all addresses from file into SQLite with batch commits
main()	Entry point, calls import function with defaults
âš¡ Performance Tips

ğŸ’¾ Use SSD storage for huge databases â€” improves insert speed drastically.

ğŸš€ Increase batch size if you have enough RAM (default 10M).

ğŸ”§ Keep PRAGMA settings as-is for fastest performance.

ğŸ§® Avoid running concurrent imports on the same DB file.

ğŸ”„ Use .VACUUM after import to optimize database size if needed.

ğŸ”’ Ethical & Legal Notice

This script is a data management utility, intended for research, analysis,
and database preparation only. It does not interact with private keys or wallets.

You may:

Import and analyze address datasets you own.

Build offline lookup databases for auditing or research.

Use for blockchain statistics or seed-check tools.

You must not:

Combine this tool with unauthorized data or illegal scraping.

Use it for private or confidential address lists without consent.

Always ensure compliance with local laws and ethical guidelines.

ğŸ§° Suggested Improvements

ğŸ“ˆ Add progress logging to file.

ğŸ’¾ Include support for .gz or .zip compressed lists.

ğŸ§® Add multiprocessing import for multi-core performance.

âš™ï¸ Support multiple database shards for parallel writes.

ğŸ§© Add resume/restart support for partial imports.

ğŸªª License

MIT License
Â© 2025 â€” Author: [Ethicbrudhack]

ğŸ’¡ Summary

This importer is a lightning-fast, memory-efficient solution
for converting huge address text files into structured SQLite databases.

âš¡ Built for speed, designed for reliability, crafted for researchers.

BTC donation address: bc1q4nyq7kr4nwq6zw35pg0zl0k9jmdmtmadlfvqhr
